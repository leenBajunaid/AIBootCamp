{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHyRaT8to7B"
      },
      "source": [
        "# Phishing Email Detection – Training and Testing Guide\n",
        "This guide explains how to train and test a simple but powerful Phishing Email Detection Model using Kaggle datasets and Google Colab.\n",
        "It walks through each step — from dataset download to real-time testing on your own email text.\n",
        "\n",
        "## Step 1: Setup and Get Data\n",
        "We start by:\n",
        "1. Installing required Python packages.\n",
        "2. Uploading the kaggle.json API token.\n",
        "3. Downloading a phishing email dataset from Kaggle.\n",
        "4. Loading and preparing the data.\n",
        "\n",
        "### Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHdKmsq4tkjf"
      },
      "outputs": [],
      "source": [
        "!pip -q install kaggle scikit-learn pandas joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clc68HvRzaMy"
      },
      "source": [
        "#### Explanation\n",
        "- `kaggle`: Access Kaggle datasets programmatically.\n",
        "- `scikit-learn`: Machine learning toolkit for training the model.\n",
        "- `pandas`: Data handling and cleaning.\n",
        "- `joblib`: For model saving/loading (optional later).\n",
        "\n",
        "--------\n",
        "### Upload your kaggle.json API Token\n",
        "This authenticates your access to Kaggle datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chrlwqDyz95X"
      },
      "outputs": [],
      "source": [
        "from google.colab import files, os\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "uploaded = files.upload()\n",
        "\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"wb\") as f:\n",
        "    f.write(uploaded['kaggle.json'])\n",
        "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVxM0GSPz_uW"
      },
      "source": [
        "#### Explanation\n",
        "\n",
        "- You’ll be prompted to upload your Kaggle API key file (kaggle.json).\n",
        "- This file is downloaded from your Kaggle account under:\n",
        "\n",
        "    **Profile → Account → Create New API Token.**\n",
        "\n",
        "- The code creates the ~/.kaggle directory and sets correct file permissions for secure access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50kEs_zx0YR5"
      },
      "source": [
        "## Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiIC5cER0aAh"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d naserabdullahalam/phishing-email-dataset -p /content -q\n",
        "!unzip -qq /content/*.zip -d /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIdqvv700eWA"
      },
      "source": [
        "#### Explanation\n",
        "- Downloads a public Phishing Email dataset from Kaggle.\n",
        "- Extracts it into /content/data for use in Colab.\n",
        "\n",
        "## Load and Inspect the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsJsJAo60jlC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, glob\n",
        "\n",
        "# Find first CSV file and load it\n",
        "csv = glob.glob(\"/content/data/**/*.csv\", recursive=True)[0]\n",
        "df = pd.read_csv(csv, encoding='latin-1').dropna()\n",
        "df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "# Identify likely text and label columns\n",
        "text_col = [c for c in df.columns if 'text' in c or 'message' in c or 'body' in c or 'email' in c][0]\n",
        "label_col = [c for c in df.columns if 'label' in c or 'class' in c or 'spam' in c or 'phish' in c][0]\n",
        "\n",
        "df = df[[text_col, label_col]].rename(columns={text_col:'text', label_col:'label'})\n",
        "print(\"✅ Loaded\", len(df), \"emails\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AFq1n_50zpc"
      },
      "source": [
        "#### Explanation:\n",
        "- Automatically finds and reads the first .csv file inside the dataset folder.\n",
        "- Cleans missing values (dropna()).\n",
        "- Detects which columns contain email text and labels based on column names.\n",
        "- Renames them to standardized columns:\n",
        "\n",
        "    `text` → email content\n",
        "\n",
        "    `label` → phishing/spam indicator\n",
        "\n",
        "- Displays the first few rows for quick inspection.\n",
        "---\n",
        "## Step 2: Train Model\n",
        "\n",
        "Now we train a lightweight, explainable model using text-based features.\n",
        "---\n",
        "Clean & Normalize Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn7w8d2j1UE6"
      },
      "outputs": [],
      "source": [
        "# --- Robust label mapping ---\n",
        "lab = df['label'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Common tokens for spam and ham classes\n",
        "SPAM_TOKENS = {'spam','phish','phishing','malicious','malware','attack','fraud','scam','bad','abusive','1','true','yes'}\n",
        "HAM_TOKENS  = {'ham','legit','legitimate','benign','normal','not_spam','0','false','no','safe'}\n",
        "\n",
        "def map_label(s):\n",
        "    # exact match first\n",
        "    if s in SPAM_TOKENS: return 1\n",
        "    if s in HAM_TOKENS:  return 0\n",
        "    # substring fallback\n",
        "    if any(t in s for t in ['spam','phish','malic','attack','fraud','scam']): return 1\n",
        "    if any(t in s for t in ['ham','legit','normal','safe']): return 0\n",
        "    # numeric fallback\n",
        "    if s.isdigit(): return int(s) if s in {'0','1'} else 0\n",
        "    return 0  # default to ham if unknown\n",
        "\n",
        "y = lab.apply(map_label).astype(int)\n",
        "X = df['text'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-lozGZj1XsJ"
      },
      "source": [
        "#### Explanation\n",
        "\n",
        "- Converts all labels to lowercase text.\n",
        "- Maps common variants of phishing/spam labels (`spam`, `phish`, `fraud`, etc.) to 1.\n",
        "- Maps safe/ham/legit labels to 0.\n",
        "- The `map_label` function ensures the dataset works even if label names differ across sources.\n",
        "\n",
        "### Clean Email Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqsmhLDI1qQw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_email(t):\n",
        "    t = t.replace('\\r','\\n')\n",
        "    cleaned_lines = []\n",
        "    for ln in t.splitlines():\n",
        "        if not re.match(r'^(from:|to:|subject:|cc:|bcc:|date:|reply-to:)', ln.strip().lower()):\n",
        "            cleaned_lines.append(ln)\n",
        "    t = '\\n'.join(cleaned_lines)\n",
        "    t = re.sub(r'\\s+', ' ', t).strip().lower()\n",
        "    return t\n",
        "\n",
        "X_clean = X.apply(clean_email)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybBOp0aK1uKI"
      },
      "source": [
        "#### Explanation\n",
        "- Removes common email header lines (e.g., From, Subject, To).\n",
        "- Normalizes whitespace and converts text to lowercase.\n",
        "- Keeps URLs and numbers, which are often critical indicators of phishing.\n",
        "\n",
        "---\n",
        "\n",
        "## Feature Extraction (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wOuywQ_15d8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "tfidf_word = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95, max_features=60000)\n",
        "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=2, max_features=60000)\n",
        "\n",
        "Xw = tfidf_word.fit_transform(X_clean)\n",
        "Xc = tfidf_char.fit_transform(X_clean)\n",
        "Xv = hstack([Xw, Xc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwGGajRcjLIm"
      },
      "outputs": [],
      "source": [
        "# === تقسيم البيانات إلى تدريب/اختبار (Train/Test Split) ===\n",
        "# نستخدم 20% للاختبار حتى نقيس الأداء على بيانات ما شافها النموذج\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    Xv, y,\n",
        "    test_size=0.20,        # نسبة الاختبار 20%\n",
        "    random_state=42,       # للتكرارية\n",
        "    stratify=y             # يحافظ على نسبة spam/ham في المجموعتين\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \" | Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep32Vd8c1-Zg"
      },
      "source": [
        "#### Explanation\n",
        "- Uses TF-IDF (Term Frequency–Inverse Document Frequency) to turn text into numerical vectors.\n",
        "\n",
        "- Two types of features are combined:\n",
        "\n",
        "- Word-level features: Capture words and short phrases (n-grams).\n",
        "\n",
        "- Character-level features: Capture URL and obfuscated word patterns often used in phishing.\n",
        "\n",
        "- The two matrices are combined using `hstack()` for a rich representation.\n",
        "\n",
        "----\n",
        "\n",
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_X4b76a2M32"
      },
      "outputs": [],
      "source": [
        "# === تدريب النموذج على مجموعة التدريب فقط ===\n",
        "# مهم: ندرب على X_train/y_train وليس كل البيانات لتجنب overfitting\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model = LinearSVC(class_weight='balanced', max_iter=3000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ Trained on\", X_train.shape[0], \"emails with\", X_train.shape[1], \"features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kDYFl7gjLIn"
      },
      "outputs": [],
      "source": [
        "# === تقييم سريع: الدقة + Precision/Recall/F1 على مجموعة الاختبار ===\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test  = model.predict(X_test)\n",
        "\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Test Accuracy    :\", accuracy_score(y_test,  y_pred_test))\n",
        "\n",
        "# نفترض أن القيمة الإيجابية هي 1 (phish/spam) لأن y أرقام 0/1 بعد المعالجة\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "    y_test, y_pred_test, pos_label=1, average=\"binary\", zero_division=0\n",
        ")\n",
        "print(f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\\n\")\n",
        "\n",
        "print(\"Classification report (test):\\n\",\n",
        "      classification_report(y_test, y_pred_test, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e541a66"
      },
      "source": [
        "### Step: Training Accuracy & Performance Graph\n",
        "This step computes the **training accuracy** of the fitted model and draws a graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ed5bd5f"
      },
      "outputs": [],
      "source": [
        "# === Simple Accuracy Graph ===\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# احسب الدقة على التدريب والاختبار\n",
        "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "test_acc  = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "# ارسم رسم بسيط يوضح الفرق بين تدريب واختبار\n",
        "labels = [\"Train\", \"Test\"]\n",
        "values = [train_acc, test_acc]\n",
        "\n",
        "plt.bar(labels, values, color=[\"skyblue\", \"orange\"])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy (Train vs Test)\")\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", fontsize=10)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRaum1BY2U4j"
      },
      "source": [
        "#### Explanation\n",
        "\n",
        "- LinearSVC (Support Vector Machine) is efficient and robust for text classification.\n",
        "\n",
        "- The `class_weight='balanced'` handles imbalance between spam and ham samples.\n",
        "\n",
        "- Trains on the TF-IDF features to learn distinguishing patterns.\n",
        "\n",
        "---\n",
        "## Step 3: Test the Model\n",
        "You can now input any text or email content to test the model’s prediction.\n",
        "---\n",
        "\n",
        "### Define the Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsUSkjBj2pKI"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "def check_email(email_text: str):\n",
        "    v_w = tfidf_word.transform([clean_email(email_text)])\n",
        "    v_c = tfidf_char.transform([clean_email(email_text)])\n",
        "    v   = hstack([v_w, v_c])\n",
        "    pred = model.predict(v)[0]\n",
        "    return \"PHISHING/SPAM\" if pred == 1 else \"Safe email\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-Z23g6B2xJZ"
      },
      "source": [
        "#### Explanation\n",
        "\n",
        "- Cleans your input email text.\n",
        "\n",
        "- Converts it into both word and character TF-IDF feature vectors.\n",
        "\n",
        "- Feeds it to the trained SVM model to predict phishing (1) or safe (0).\n",
        "\n",
        "### Try Example Emails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1mFr9WA27-h"
      },
      "outputs": [],
      "source": [
        "print(check_email(\"Your account has been locked. Verify now at http://fakebank.com\"))\n",
        "print(check_email(\"Hi John, attached are the meeting minutes for today.\"))\n",
        "print(check_email(\"Hey did you check this picture before, its great landscape http://someoddpic.sm\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKgG-Lm22_Xa"
      },
      "source": [
        "#### Expected Output\n",
        "\n",
        "```\n",
        "PHISHING/SPAM\n",
        "Safe email\n",
        "PHISHING/SPAM\n",
        "```\n",
        "\n",
        "## Summary\n",
        "| Step                      | Description                                |\n",
        "| ------------------------- | ------------------------------------------ |\n",
        "| **1. Setup**              | Install dependencies & authenticate Kaggle |\n",
        "| **2. Download Data**      | Get a real phishing dataset                |\n",
        "| **3. Preprocess**         | Clean text and normalize labels            |\n",
        "| **4. Feature Extraction** | TF-IDF on words + characters               |\n",
        "| **5. Train Model**        | Linear SVM classifier                      |\n",
        "| **6. Test Model**         | Predict phishing vs safe emails            |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}